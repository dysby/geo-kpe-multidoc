{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-0921.xlsx\")\n",
    "# wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-0926.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'mmr', 'top_n', 'weights', 'doc_name', 'doc_limit',\n",
       "       'whitening', 'batch_size', 'kp_min_len', 'rank_model', 'embed_model',\n",
       "       'max_seq_len', 'md_strategy', 'no_stemming', 'tagger_name',\n",
       "       'dataset_name', 'kp_max_words', 'cache_results', 'ensemble_mode',\n",
       "       'lemmatization', 'mmr_diversity', 'preprocessing', 'cache_pos_tags',\n",
       "       'candidate_mode', 'dataset_source', 'decoder_prompt', 'encoder_prompt',\n",
       "       'experiment_name', 'add_query_prefix', 'cache_embeddings',\n",
       "       'extraction_variant', 'cache_md_embeddings', 'no_position_feature',\n",
       "       'longformer_max_length', 'cache_candidate_selection',\n",
       "       'longformer_attention_window', 'longformer_only_copy_to_max_position',\n",
       "       'geo_alpha', 'geo_weight_function', 'geo_association_index',\n",
       "       'geo_weight_function_param', 'min_len', 'embedrank_mmr', 'pooling',\n",
       "       'embedrank_diversity', 'F1_15', 'Recall', 'Recall_10', 'F1', 'MAP',\n",
       "       'nDCG', '_base_F1', '_base_Recall_5', '_base_Precision',\n",
       "       '_base_Precision_5', 'F1_10', '_step', 'Precision', '_base_nDCG',\n",
       "       'Precision_10', '_base_Recall', '_base_Precision_10',\n",
       "       'first-doc-extraction-sample', 'Recall_5', 'Recall_15', '_base_MAP',\n",
       "       '_timestamp', '_base_F1_10', 'Precision_15', '_base_F1_15',\n",
       "       '_base_Recall_15', '_base_Precision_15', '_base_F1_5',\n",
       "       '_base_Recall_10', 'F1_5', '_runtime', 'Precision_5', '_wandb.runtime',\n",
       "       'score_distribution.path', 'score_distribution.size',\n",
       "       'score_distribution._type', 'score_distribution.width',\n",
       "       'score_distribution.format', 'score_distribution.height',\n",
       "       'score_distribution.sha256'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (wandb[[\"longformer_attention_window\", \"candidate_mode\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]][wandb.experiment_name == \"Longformer-att-wind\"]\n",
    "   .set_index([\"longformer_attention_window\", \"candidate_mode\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>longformer_attention_window</th>\n",
       "      <th>512.0</th>\n",
       "      <th>256.0</th>\n",
       "      <th>128.0</th>\n",
       "      <th>64.0</th>\n",
       "      <th>512.0</th>\n",
       "      <th>256.0</th>\n",
       "      <th>128.0</th>\n",
       "      <th>64.0</th>\n",
       "      <th>512.0</th>\n",
       "      <th>256.0</th>\n",
       "      <th>128.0</th>\n",
       "      <th>512.0</th>\n",
       "      <th>256.0</th>\n",
       "      <th>128.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">64.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_mode</th>\n",
       "      <th>mentions_no_context</th>\n",
       "      <th>mentions_no_context</th>\n",
       "      <th>mentions_no_context</th>\n",
       "      <th>mentions_no_context</th>\n",
       "      <th>global_attention_dilated_128</th>\n",
       "      <th>global_attention_dilated_128</th>\n",
       "      <th>global_attention_dilated_128</th>\n",
       "      <th>global_attention_dilated_128</th>\n",
       "      <th>global_attention</th>\n",
       "      <th>global_attention</th>\n",
       "      <th>global_attention</th>\n",
       "      <th>in_context</th>\n",
       "      <th>in_context</th>\n",
       "      <th>in_context</th>\n",
       "      <th>in_context</th>\n",
       "      <th>in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_base_nDCG</th>\n",
       "      <td>0.544621</td>\n",
       "      <td>0.501696</td>\n",
       "      <td>0.457237</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.410577</td>\n",
       "      <td>0.407363</td>\n",
       "      <td>0.410031</td>\n",
       "      <td>0.412999</td>\n",
       "      <td>0.368239</td>\n",
       "      <td>0.368956</td>\n",
       "      <td>0.368529</td>\n",
       "      <td>0.412498</td>\n",
       "      <td>0.408777</td>\n",
       "      <td>0.413667</td>\n",
       "      <td>0.415210</td>\n",
       "      <td>0.474530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_base_F1_5</th>\n",
       "      <td>0.234406</td>\n",
       "      <td>0.190878</td>\n",
       "      <td>0.154156</td>\n",
       "      <td>0.114256</td>\n",
       "      <td>0.100317</td>\n",
       "      <td>0.095856</td>\n",
       "      <td>0.098871</td>\n",
       "      <td>0.104219</td>\n",
       "      <td>0.052901</td>\n",
       "      <td>0.053771</td>\n",
       "      <td>0.053910</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>0.098964</td>\n",
       "      <td>0.103909</td>\n",
       "      <td>0.112133</td>\n",
       "      <td>0.154272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_base_F1_10</th>\n",
       "      <td>0.275882</td>\n",
       "      <td>0.237369</td>\n",
       "      <td>0.183212</td>\n",
       "      <td>0.134136</td>\n",
       "      <td>0.128109</td>\n",
       "      <td>0.122892</td>\n",
       "      <td>0.136391</td>\n",
       "      <td>0.136783</td>\n",
       "      <td>0.077928</td>\n",
       "      <td>0.076883</td>\n",
       "      <td>0.078427</td>\n",
       "      <td>0.132462</td>\n",
       "      <td>0.121674</td>\n",
       "      <td>0.133657</td>\n",
       "      <td>0.138391</td>\n",
       "      <td>0.191189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_base_F1_15</th>\n",
       "      <td>0.276890</td>\n",
       "      <td>0.238394</td>\n",
       "      <td>0.188880</td>\n",
       "      <td>0.140827</td>\n",
       "      <td>0.137299</td>\n",
       "      <td>0.135276</td>\n",
       "      <td>0.137991</td>\n",
       "      <td>0.140141</td>\n",
       "      <td>0.092349</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>0.096001</td>\n",
       "      <td>0.135588</td>\n",
       "      <td>0.132872</td>\n",
       "      <td>0.143426</td>\n",
       "      <td>0.146284</td>\n",
       "      <td>0.209415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "longformer_attention_window               512.0               256.0  \\\n",
       "candidate_mode              mentions_no_context mentions_no_context   \n",
       "_base_nDCG                             0.544621            0.501696   \n",
       "_base_F1_5                             0.234406            0.190878   \n",
       "_base_F1_10                            0.275882            0.237369   \n",
       "_base_F1_15                            0.276890            0.238394   \n",
       "\n",
       "longformer_attention_window               128.0               64.0   \\\n",
       "candidate_mode              mentions_no_context mentions_no_context   \n",
       "_base_nDCG                             0.457237            0.412061   \n",
       "_base_F1_5                             0.154156            0.114256   \n",
       "_base_F1_10                            0.183212            0.134136   \n",
       "_base_F1_15                            0.188880            0.140827   \n",
       "\n",
       "longformer_attention_window                        512.0  \\\n",
       "candidate_mode              global_attention_dilated_128   \n",
       "_base_nDCG                                      0.410577   \n",
       "_base_F1_5                                      0.100317   \n",
       "_base_F1_10                                     0.128109   \n",
       "_base_F1_15                                     0.137299   \n",
       "\n",
       "longformer_attention_window                        256.0  \\\n",
       "candidate_mode              global_attention_dilated_128   \n",
       "_base_nDCG                                      0.407363   \n",
       "_base_F1_5                                      0.095856   \n",
       "_base_F1_10                                     0.122892   \n",
       "_base_F1_15                                     0.135276   \n",
       "\n",
       "longformer_attention_window                        128.0  \\\n",
       "candidate_mode              global_attention_dilated_128   \n",
       "_base_nDCG                                      0.410031   \n",
       "_base_F1_5                                      0.098871   \n",
       "_base_F1_10                                     0.136391   \n",
       "_base_F1_15                                     0.137991   \n",
       "\n",
       "longformer_attention_window                        64.0             512.0  \\\n",
       "candidate_mode              global_attention_dilated_128 global_attention   \n",
       "_base_nDCG                                      0.412999         0.368239   \n",
       "_base_F1_5                                      0.104219         0.052901   \n",
       "_base_F1_10                                     0.136783         0.077928   \n",
       "_base_F1_15                                     0.140141         0.092349   \n",
       "\n",
       "longformer_attention_window            256.0            128.0      512.0  \\\n",
       "candidate_mode              global_attention global_attention in_context   \n",
       "_base_nDCG                          0.368956         0.368529   0.412498   \n",
       "_base_F1_5                          0.053771         0.053910   0.104828   \n",
       "_base_F1_10                         0.076883         0.078427   0.132462   \n",
       "_base_F1_15                         0.094773         0.096001   0.135588   \n",
       "\n",
       "longformer_attention_window      256.0      128.0      64.0              \n",
       "candidate_mode              in_context in_context in_context in_context  \n",
       "_base_nDCG                    0.408777   0.413667   0.415210   0.474530  \n",
       "_base_F1_5                    0.098964   0.103909   0.112133   0.154272  \n",
       "_base_F1_10                   0.121674   0.133657   0.138391   0.191189  \n",
       "_base_F1_15                   0.132872   0.143426   0.146284   0.209415  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          _base_nDCG  _base_F1_5  _base_F1_10  _base_F1_15\n",
      "longformer_attention_window candidate_mode                                                                \n",
      "64.0                        global_attention_dilated_128       41.30       10.42        13.68        14.01\n",
      "                            in_context                         41.52       11.21        13.84        14.63\n",
      "                            in_context                         47.45       15.43        19.12        20.94\n",
      "                            mentions_no_context                41.21       11.43        13.41        14.08\n",
      "128.0                       global_attention                   36.85        5.39         7.84         9.60\n",
      "                            global_attention_dilated_128       41.00        9.89        13.64        13.80\n",
      "                            in_context                         41.37       10.39        13.37        14.34\n",
      "                            mentions_no_context                45.72       15.42        18.32        18.89\n",
      "256.0                       global_attention                   36.90        5.38         7.69         9.48\n",
      "                            global_attention_dilated_128       40.74        9.59        12.29        13.53\n",
      "                            in_context                         40.88        9.90        12.17        13.29\n",
      "                            mentions_no_context                50.17       19.09        23.74        23.84\n",
      "512.0                       global_attention                   36.82        5.29         7.79         9.23\n",
      "                            global_attention_dilated_128       41.06       10.03        12.81        13.73\n",
      "                            in_context                         41.25       10.48        13.25        13.56\n",
      "                            mentions_no_context                54.46       23.44        27.59        27.69\n"
     ]
    }
   ],
   "source": [
    "print(((wandb[[\"longformer_attention_window\", \"candidate_mode\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]][wandb.experiment_name == \"Longformer-att-wind\"]\n",
    "   .set_index([\"longformer_attention_window\", \"candidate_mode\"]).sort_index()).round(decimals=4)*100).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "candidate_mode & \\multicolumn{4}{r}{in_context} & \\multicolumn{4}{r}{global_attention} & \\multicolumn{4}{r}{global_attention_dilated_128} \\\\\n",
      " & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 \\\\\n",
      "longformer_attention_window &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "64.000000 & \\textbf{41.52} & \\textbf{11.21} & \\textbf{13.84} & \\textbf{14.63} & nan & nan & nan & nan & \\textbf{41.30} & \\textbf{10.42} & \\textbf{13.68} & \\textbf{14.01} \\\\\n",
      "128.000000 & 41.37 & 10.39 & 13.37 & 14.34 & 36.85 & \\textbf{5.39} & \\textbf{7.84} & \\textbf{9.60} & 41.00 & 9.89 & 13.64 & 13.80 \\\\\n",
      "256.000000 & 40.88 & 9.90 & 12.17 & 13.29 & \\textbf{36.90} & 5.38 & 7.69 & 9.48 & 40.74 & 9.59 & 12.29 & 13.53 \\\\\n",
      "512.000000 & 41.25 & 10.48 & 13.25 & 13.56 & 36.82 & 5.29 & 7.79 & 9.23 & 41.06 & 10.03 & 12.81 & 13.73 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((t.reset_index().drop(15).set_index([\"longformer_attention_window\", \"candidate_mode\"]).unstack(1).swaplevel(0, 1, axis=1).transpose()\n",
    "    #.loc[(slice(\"in_context\", \"global_attention\", \"global_attention_dilated_128\"), slice(None))]\n",
    "    .loc[pd.IndexSlice[[\"mentions_no_context\", \"in_context\", 'global_attention', \"global_attention_dilated_128\"],]]\n",
    "    .transpose()*100\n",
    ").style.format(precision=2).highlight_max(\n",
    "    # props='bfseries:;'\n",
    "    props='textbf:--rwrap'\n",
    ").to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-1011.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "kp_max_words & \\multicolumn{2}{r}{7.000000} & \\multicolumn{2}{r}{nan} \\\\\n",
      " & _base_Recall & Recall & _base_Recall & Recall \\\\\n",
      "dataset_name &  &  &  &  \\\\\n",
      "DUC2001 & 86.78 & 84.35 & 86.78 & 84.35 \\\\\n",
      "Inspec & 59.15 & 57.52 & 59.22 & 57.58 \\\\\n",
      "NUS & 88.96 & 73.81 & 89.05 & 73.96 \\\\\n",
      "PubMed & 77.01 & 69.38 & 77.08 & 69.44 \\\\\n",
      "SemEval2010 & 87.55 & 71.50 & 87.57 & 71.57 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1011.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ (13,14,15,16,17,18,19,20,22,23) ]\n",
    "# \"lemmatization\"\n",
    "# idx = pd.IndexSlice[ (1,2,3,4,5,6,7,8,9,10) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"kp_max_words\",\n",
    "            \"dataset_name\",\n",
    "            \"_base_Recall\",\n",
    "            \"Recall\"\n",
    "           #  \"decoder_prompt\",\n",
    "            # \"_base_nDCG\",\n",
    "            # \"_base_F1_5\",\n",
    "            # \"_base_F1_10\",\n",
    "            # \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"dataset_name\", \"kp_max_words\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [7, pd.NA],\n",
    "        [\"_base_Recall\", \"Recall\"],\n",
    "    ]\n",
    ")\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "            # \"_base_Recall\": \"Recall\",\n",
    "        },\n",
    "        level=1,\n",
    "    )\n",
    "    .style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmbedRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-1001.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrl}\n",
      " & dataset_name & \\multicolumn{5}{r}{PubMed} \\\\\n",
      " &  & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "candidate_mode & embed_model &  &  &  &  &  \\\\\n",
      "\\multirow[c]{3}{*}{in\\_context} & intfloat/e5-base-v2 & 29.46 & 3.97 & 6.01 & 7.26 &  \\\\\n",
      " & paraphrase-multilingual-mpnet-base-v2 & 30.76 & 5.54 & 8.42 & 10.23 &  \\\\\n",
      " & sentence-transformers/sentence-t5-base & 20.13 & 1.42 & 1.91 & 2.08 &  \\\\\n",
      "\\multirow[c]{3}{*}{mentions\\_no\\_context} & intfloat/e5-base-v2 & 30.34 & 6.12 & 7.77 & 8.21 &  \\\\\n",
      " & paraphrase-multilingual-mpnet-base-v2 & 28.54 & 5.68 & 6.86 & 7.06 &  \\\\\n",
      " & sentence-transformers/sentence-t5-base & 27.10 & 4.08 & 5.37 & 5.79 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1001.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ ( 10,11,12,15,18,24) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"embed_model\",\n",
    "            \"candidate_mode\",\n",
    "            \"dataset_name\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"candidate_mode\", \"dataset_name\", \"embed_model\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"PubMed\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-1011.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrlrrrrlrrrrlrrrrlrrrrl}\n",
      "dataset_name & \\multicolumn{5}{r}{DUC2001} & \\multicolumn{5}{r}{NUS} & \\multicolumn{5}{r}{Inspec} & \\multicolumn{5}{r}{SemEval2010} & \\multicolumn{5}{r}{PubMed} \\\\\n",
      " & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  \\\\\n",
      "embed_model &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "[longformer]intfloat/e5-base-v2 & 36.82 & 5.29 & 7.79 & 9.23 &  & 32.91 & 2.15 & 3.28 & 3.63 &  & 44.73 & 21.43 & 29.48 & 32.40 &  & 35.04 & 2.10 & 3.26 & 4.01 &  & 22.44 & 1.60 & 2.38 & 2.65 &  \\\\\n",
      "[longformer]paraphrase-multilingual-mpnet-base-v2 & 38.82 & 7.41 & 9.99 & 12.06 &  & 34.51 & 1.77 & 3.62 & 4.05 &  & 43.37 & 19.73 & 26.79 & 30.04 &  & 36.33 & 1.60 & 2.63 & 3.39 &  & 21.52 & 0.98 & 1.35 & 1.54 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1011.xlsx\n",
    "# fmt: off\n",
    "# \"lemmatization\"\n",
    "idx = pd.IndexSlice[ ( 24,26,27,28,29,30,31,32,33,34) ]\n",
    "# no lemmatization\n",
    "idx = pd.IndexSlice[ (41,42,44,45,46,47,48,49,50,51) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"embed_model\",\n",
    "            \"dataset_name\",\n",
    "            # \"_base_Recall\",\n",
    "            # \"Recall\"\n",
    "           #  \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"embed_model\", \"dataset_name\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_{@5}$\",\n",
    "            \"_base_F1_10\": \"$F1_{@10}$\",\n",
    "            \"_base_F1_15\": \"$F1@_{@15}$\",\n",
    "            \"empty\": \"\",\n",
    "            # \"_base_Recall\": \"Recall\",\n",
    "        },\n",
    "        level=1,\n",
    "    )\n",
    "    .style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ah-doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PromptRank - Long models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrlrrrrlrrrrlrrrrlrrrrl}\n",
      "dataset_name & \\multicolumn{5}{r}{DUC2001} & \\multicolumn{5}{r}{NUS} & \\multicolumn{5}{r}{Inspec} & \\multicolumn{5}{r}{SemEval2010} & \\multicolumn{5}{r}{PubMed} \\\\\n",
      " & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  & nDCG & $F1_{@5}$ & $F1_{@10}$ & $F1@_{@15}$ &  \\\\\n",
      "embed_model &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "google/long-t5-tglobal-base & 58.26 & 27.14 & 30.45 & 29.82 &  & 56.25 & 19.93 & 20.18 & 19.89 &  & 51.47 & 28.91 & 34.44 & 35.03 &  & 49.83 & 9.76 & 11.78 & 13.72 &  & 35.48 & 12.86 & 14.12 & 13.47 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1011.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ (68,318,322,378,389) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"embed_model\",\n",
    "            \"dataset_name\",\n",
    "            # \"_base_Recall\",\n",
    "            # \"Recall\"\n",
    "           #  \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"embed_model\", \"dataset_name\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_{@5}$\",\n",
    "            \"_base_F1_10\": \"$F1_{@10}$\",\n",
    "            \"_base_F1_15\": \"$F1@_{@15}$\",\n",
    "            \"empty\": \"\",\n",
    "            # \"_base_Recall\": \"Recall\",\n",
    "        },\n",
    "        level=1,\n",
    "    )\n",
    "    .style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrrrrrrrr}\n",
      " & dataset_name & \\multicolumn{4}{r}{DUC2001} & \\multicolumn{4}{r}{NUS} & \\multicolumn{4}{r}{Inspec} & \\multicolumn{4}{r}{SemEval2010} \\\\\n",
      " &  & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 \\\\\n",
      "embed_model & decoder_prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\multirow[c]{2}{*}{google/long-t5-tglobal-base} & nan & 58.26 & 27.14 & 30.45 & 29.82 & 56.25 & 19.93 & 20.18 & 19.89 & 51.47 & 28.91 & 34.44 & 35.03 & 49.83 & 9.76 & 11.78 & 13.72 \\\\\n",
      " & TL;DR: This book mainly talks about  & 57.80 & 26.47 & 29.96 & 29.65 & 56.04 & 20.24 & 20.06 & 19.75 & 51.35 & 28.56 & 33.58 & 34.41 & 50.01 & 10.34 & 12.45 & 13.79 \\\\\n",
      "\\multirow[c]{2}{*}{tau/t5-v1_1-base-sled} & nan & 51.50 & 19.57 & 23.95 & 24.07 & 54.86 & 18.72 & 17.86 & 17.97 & 46.65 & 23.25 & 28.54 & 29.99 & 48.95 & 9.47 & 11.35 & 13.13 \\\\\n",
      " & TL;DR: This book mainly talks about  & nan & nan & nan & nan & nan & nan & nan & nan & 34.48 & 7.95 & 14.45 & 19.94 & 49.11 & 10.27 & 12.69 & 13.76 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = (wandb[[\"embed_model\", \"decoder_prompt\", \"dataset_name\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]][(wandb.rank_model == \"PromptRank\") & (wandb.embed_model.isin([\"tau/t5-v1_1-base-sled\", \"google/long-t5-tglobal-base\"]))  ]\n",
    "         .drop(1012) # no_position_feature\n",
    "         .set_index([\"embed_model\",\"decoder_prompt\", \"dataset_name\"]).sort_index().unstack(2).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "         # .loc[:, pd.IndexSlice[:,[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]]\n",
    ")\n",
    "\n",
    "mi = pd.MultiIndex.from_product([[\"DUC2001\",\"NUS\", \"Inspec\",\"SemEval2010\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print((t*100)[mi].style.format(precision=2)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "# [\"tau/t5-v1_1-base-sled\", \"google/long-t5-tglobal-base\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrrrrrrrrrrrr}\n",
      " & dataset_name & \\multicolumn{4}{r}{DUC2001} & \\multicolumn{4}{r}{Inspec} & \\multicolumn{4}{r}{NUS} & \\multicolumn{4}{r}{SemEval2010} & \\multicolumn{4}{r}{PubMed} \\\\\n",
      " &  & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 \\\\\n",
      "embed_model & decoder_prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\multirow[c]{3}{*}{google/flan-t5-base} & nan & 58.59 & 27.76 & 30.74 & 30.85 & 53.68 & 31.65 & 35.83 & 35.70 & 58.09 & 22.62 & 24.12 & 23.24 & 53.40 & 15.99 & 19.10 & 20.25 & 42.38 & 17.23 & 17.76 & 16.29 \\\\\n",
      " & Summary:  & 56.30 & 24.81 & 28.88 & 28.22 & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan \\\\\n",
      " & TL;DR: This book mainly talks about  & 59.53 & 28.85 & 31.70 & 31.30 & 53.72 & 31.62 & 35.83 & 35.67 & 58.21 & 22.71 & 23.81 & 23.22 & 53.62 & 15.99 & 19.47 & 20.24 & 41.95 & 17.19 & 17.31 & 15.92 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = (wandb[[\"embed_model\", \"decoder_prompt\", \"dataset_name\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]][(wandb.rank_model == \"PromptRank\") & (wandb.embed_model.isin([\"google/flan-t5-base\"]))  ]\n",
    "       .loc[[122, 143, 144, 148, 149, 150, 151, 156 ,157, 159, 897], :]\n",
    "       .set_index([\"embed_model\",\"decoder_prompt\", \"dataset_name\"]).unstack(2).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "\n",
    "  # .set_index([\"embed_model\",\"decoder_prompt\", \"dataset_name\"]).sort_index()\n",
    "         #.unstack(2).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "         # .loc[:, pd.IndexSlice[:,[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]]\n",
    ")\n",
    "mi = pd.MultiIndex.from_product([[\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "print(\n",
    "(t*100)[mi].style.format(precision=2)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "# [\"tau/t5-v1_1-base-sled\", \"google/long-t5-tglobal-base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrrrrrrrr}\n",
      "dataset_name & \\multicolumn{4}{r}{DUC2001} & \\multicolumn{4}{r}{NUS} & \\multicolumn{4}{r}{Inspec} & \\multicolumn{4}{r}{SemEval2010} & \\multicolumn{4}{r}{PubMed} \\\\\n",
      " & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 \\\\\n",
      "embed_model &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "sentence-transformers/sentence-t5-base & 65.40 & 35.46 & 38.89 & 36.35 & 54.24 & 17.41 & 22.03 & 22.22 & 52.42 & 30.51 & 35.75 & 35.74 & 54.12 & 16.26 & 20.14 & 21.50 & 34.99 & 10.79 & 12.77 & 12.91 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embedrank sentence-transformer-t5 (+pos)\n",
    "t = (wandb[[\"embed_model\", \"dataset_name\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]\n",
    "       .loc[[115,129,133,138,141 ], :]\n",
    "       .set_index([\"embed_model\",\"dataset_name\"]).unstack(1).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "\n",
    "  # .set_index([\"embed_model\",\"decoder_prompt\", \"dataset_name\"]).sort_index()\n",
    "         #.unstack(2).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "         # .loc[:, pd.IndexSlice[:,[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]]\n",
    ")\n",
    "\n",
    "\n",
    "mi = pd.MultiIndex.from_product([[\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "(t*100)[mi].style.format(precision=2)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "# [\"tau/t5-v1_1-base-sled\", \"google/long-t5-tglobal-base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrrrrrrrr}\n",
      " & md_strategy & \\multicolumn{4}{r}{RRF} & \\multicolumn{4}{r}{MEAN} & \\multicolumn{4}{r}{MEANTOPMAX} & \\multicolumn{4}{r}{MAX} \\\\\n",
      " &  & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 \\\\\n",
      "embed_model & decoder_prompt &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "t5-base & TL;DR: This book mainly talks about  & 53.20 & 3.82 & 6.52 & 10.12 & 54.37 & 5.78 & 8.57 & 10.12 & 55.21 & 5.04 & 7.81 & 10.25 & 59.29 & 6.68 & 10.82 & 14.08 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = (wandb[[\"embed_model\", \"decoder_prompt\", \"md_strategy\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]\n",
    "       .loc[[50 ,51 ,52 ,75], :]\n",
    "       .set_index([\"embed_model\",\"decoder_prompt\", \"md_strategy\"]).unstack(2).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "\n",
    "  # .set_index([\"embed_model\",\"decoder_prompt\", \"dataset_name\"]).sort_index()\n",
    "         #.unstack(2).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "         # .loc[:, pd.IndexSlice[:,[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]]\n",
    ")\n",
    "mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "(t*100)[mi].style.format(precision=2)\n",
    "    #.highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "# [\"tau/t5-v1_1-base-sled\", \"google/long-t5-tglobal-base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>md_strategy</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RRF</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MEAN</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MEANTOPMAX</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>_base_nDCG</th>\n",
       "      <th>_base_F1_5</th>\n",
       "      <th>_base_F1_10</th>\n",
       "      <th>_base_F1_15</th>\n",
       "      <th>_base_nDCG</th>\n",
       "      <th>_base_F1_5</th>\n",
       "      <th>_base_F1_10</th>\n",
       "      <th>_base_F1_15</th>\n",
       "      <th>_base_nDCG</th>\n",
       "      <th>_base_F1_5</th>\n",
       "      <th>_base_F1_10</th>\n",
       "      <th>_base_F1_15</th>\n",
       "      <th>_base_nDCG</th>\n",
       "      <th>_base_F1_5</th>\n",
       "      <th>_base_F1_10</th>\n",
       "      <th>_base_F1_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_model</th>\n",
       "      <th>decoder_prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5-base</th>\n",
       "      <th>TL;DR: This book mainly talks about</th>\n",
       "      <td>0.532014</td>\n",
       "      <td>0.038222</td>\n",
       "      <td>0.06524</td>\n",
       "      <td>0.101172</td>\n",
       "      <td>0.543685</td>\n",
       "      <td>0.057799</td>\n",
       "      <td>0.085657</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>0.55215</td>\n",
       "      <td>0.050418</td>\n",
       "      <td>0.07805</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>0.59288</td>\n",
       "      <td>0.06675</td>\n",
       "      <td>0.108182</td>\n",
       "      <td>0.140774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "md_strategy                                             RRF             \\\n",
       "                                                 _base_nDCG _base_F1_5   \n",
       "embed_model decoder_prompt                                               \n",
       "t5-base     TL;DR: This book mainly talks about    0.532014   0.038222   \n",
       "\n",
       "md_strategy                                                               \\\n",
       "                                                 _base_F1_10 _base_F1_15   \n",
       "embed_model decoder_prompt                                                 \n",
       "t5-base     TL;DR: This book mainly talks about      0.06524    0.101172   \n",
       "\n",
       "md_strategy                                            MEAN             \\\n",
       "                                                 _base_nDCG _base_F1_5   \n",
       "embed_model decoder_prompt                                               \n",
       "t5-base     TL;DR: This book mainly talks about    0.543685   0.057799   \n",
       "\n",
       "md_strategy                                                               \\\n",
       "                                                 _base_F1_10 _base_F1_15   \n",
       "embed_model decoder_prompt                                                 \n",
       "t5-base     TL;DR: This book mainly talks about     0.085657    0.101182   \n",
       "\n",
       "md_strategy                                      MEANTOPMAX             \\\n",
       "                                                 _base_nDCG _base_F1_5   \n",
       "embed_model decoder_prompt                                               \n",
       "t5-base     TL;DR: This book mainly talks about     0.55215   0.050418   \n",
       "\n",
       "md_strategy                                                               \\\n",
       "                                                 _base_F1_10 _base_F1_15   \n",
       "embed_model decoder_prompt                                                 \n",
       "t5-base     TL;DR: This book mainly talks about      0.07805    0.102468   \n",
       "\n",
       "md_strategy                                             MAX             \\\n",
       "                                                 _base_nDCG _base_F1_5   \n",
       "embed_model decoder_prompt                                               \n",
       "t5-base     TL;DR: This book mainly talks about     0.59288    0.06675   \n",
       "\n",
       "md_strategy                                                               \n",
       "                                                 _base_F1_10 _base_F1_15  \n",
       "embed_model decoder_prompt                                                \n",
       "t5-base     TL;DR: This book mainly talks about     0.108182    0.140774  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[mi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "geo_association_index & \\multicolumn{4}{r}{moran_i} \\\\\n",
      " & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 \\\\\n",
      "experiment_name &  &  &  &  \\\\\n",
      "MKDUC01-MdPromptRank-11834 & 52.97 & 5.21 & 6.92 & 9.20 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GEO\n",
    "# \"geo_alpha\"\n",
    "t = (wandb[[\"experiment_name\", \"geo_association_index\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]\n",
    "       .loc[[885], :]\n",
    "       .set_index([\"experiment_name\",\"geo_association_index\" ]).unstack(1).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "\n",
    "  # .set_index([\"embed_model\",\"decoder_prompt\", \"dataset_name\"]).sort_index()\n",
    "         #.unstack(2).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    "         # .loc[:, pd.IndexSlice[:,[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]]]\n",
    ")\n",
    "mi = pd.MultiIndex.from_product([[\"moran_i\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "t[mi]\n",
    "print(\n",
    "(t*100)[mi].style.format(precision=2)\n",
    "    #.highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "# [\"tau/t5-v1_1-base-sled\", \"google/long-t5-tglobal-base\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>geo_association_index</th>\n",
       "      <th colspan=\"4\" halign=\"left\">moran_i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>_base_nDCG</th>\n",
       "      <th>_base_F1_5</th>\n",
       "      <th>_base_F1_10</th>\n",
       "      <th>_base_F1_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKDUC01-MdPromptRank-11834</th>\n",
       "      <td>0.529706</td>\n",
       "      <td>0.052132</td>\n",
       "      <td>0.06924</td>\n",
       "      <td>0.09201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "geo_association_index         moran_i                                   \n",
       "                           _base_nDCG _base_F1_5 _base_F1_10 _base_F1_15\n",
       "experiment_name                                                         \n",
       "MKDUC01-MdPromptRank-11834   0.529706   0.052132     0.06924     0.09201"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[mi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chp 2 - sbert by max_seq_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-0926.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrlrrrrlrrrrlrrrrl}\n",
      " & dataset_name & \\multicolumn{5}{r}{DUC2001} & \\multicolumn{5}{r}{NUS} & \\multicolumn{5}{r}{Inspec} & \\multicolumn{5}{r}{SemEval2010} \\\\\n",
      " &  & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & empty & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & empty & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & empty & _base_nDCG & _base_F1_5 & _base_F1_10 & _base_F1_15 & empty \\\\\n",
      "max_seq_len & candidate_mode &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\multirow[c]{2}{*}{128.000000} & in_context & 48.49 & 15.29 & 21.56 & 23.02 &  & 46.23 & 8.12 & 13.82 & 16.85 &  & 44.02 & 20.65 & 27.87 & 30.07 &  & 42.10 & 4.10 & 8.90 & 12.04 &  \\\\\n",
      " & mentions_no_context & nan & nan & nan & nan & nan & 45.36 & 9.18 & 11.43 & 13.04 &  & 50.45 & 27.66 & 33.14 & 33.62 &  & 44.70 & 8.63 & 11.41 & 12.75 &  \\\\\n",
      "\\multirow[c]{2}{*}{256.000000} & in_context & 46.18 & 12.63 & 18.49 & 20.86 &  & 45.66 & 6.51 & 11.15 & 14.01 &  & 43.41 & 19.79 & 26.95 & 30.16 &  & 45.03 & 7.04 & 11.33 & 13.96 &  \\\\\n",
      " & mentions_no_context & 57.34 & 25.44 & 29.64 & 29.82 &  & 41.88 & 5.90 & 8.34 & 10.16 &  & 49.86 & 27.09 & 32.39 & 33.25 &  & 42.33 & 5.42 & 8.87 & 10.24 &  \\\\\n",
      "\\multirow[c]{2}{*}{384.000000} & in_context & 43.86 & 10.03 & 15.54 & 18.48 &  & 44.54 & 6.26 & 9.51 & 11.57 &  & 43.38 & 19.78 & 26.81 & 30.07 &  & 44.61 & 5.80 & 9.35 & 12.33 &  \\\\\n",
      " & mentions_no_context & 54.43 & 22.59 & 26.53 & 27.69 &  & 39.97 & 4.84 & 7.89 & 8.98 &  & 49.60 & 26.86 & 32.18 & 33.02 &  & 40.41 & 4.49 & 7.50 & 8.67 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0926.xlsx\n",
    "idx = pd.IndexSlice[(0, 1, 3, 2, 4, 5, 7, 6, 8, 9, 11, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 21)]\n",
    "\n",
    "t = (wandb[[\"max_seq_len\", \"candidate_mode\", \"dataset_name\", \"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]].loc[idx, :]\n",
    "   .set_index([\"max_seq_len\", \"dataset_name\", \"candidate_mode\"]).assign(empty = '').unstack(1).swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)\n",
    ")\n",
    "\n",
    "mi = pd.MultiIndex.from_product([[\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"]])\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "print(\n",
    "(t*100)[mi].style.format(precision=2)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-1026.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrl}\n",
      " & dataset_name & \\multicolumn{5}{r}{PubMed} \\\\\n",
      " &  & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "max_seq_len & candidate_mode &  &  &  &  &  \\\\\n",
      "\\multirow[c]{2}{*}{128.000000} & in\\_context & 30.76 & 5.54 & 8.42 & 10.23 &  \\\\\n",
      " & mentions\\_no\\_context & 28.54 & 5.68 & 6.86 & 7.06 &  \\\\\n",
      "\\multirow[c]{2}{*}{256.000000} & in\\_context & 29.22 & 3.58 & 6.10 & 7.58 &  \\\\\n",
      " & mentions\\_no\\_context & 25.76 & 2.92 & 4.25 & 5.06 &  \\\\\n",
      "\\multirow[c]{2}{*}{384.000000} & in\\_context & 28.32 & 2.88 & 4.51 & 6.13 &  \\\\\n",
      " & mentions\\_no\\_context & 24.76 & 2.35 & 3.50 & 4.12 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1026.xlsx\n",
    "# fmt: off\n",
    "# idx = pd.IndexSlice[ (9,10,11,12) ] # prompt cross\n",
    "idx = pd.IndexSlice[ (46, 47,48,49,50,51) ] # prompt no-cross\n",
    "# idx = pd.IndexSlice[ (0,1,2,3,4) ] # embed cross (-pos)\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"max_seq_len\", \"candidate_mode\", \"dataset_name\",\n",
    "            \"nDCG\",\n",
    "            \"F1_5\",\n",
    "            \"F1_10\",\n",
    "            \"F1_15\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"max_seq_len\", \"candidate_mode\", \"dataset_name\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(-1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"PubMed\"],\n",
    "        [\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "            \"F1_5\": \"$F1_5$\",\n",
    "            \"F1_10\": \"$F1_{10}$\",\n",
    "            \"F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chp 2 - short model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrlrrrrlrrrrlrrrrl}\n",
      " & dataset_name & \\multicolumn{5}{r}{DUC2001} & \\multicolumn{5}{r}{NUS} & \\multicolumn{5}{r}{Inspec} & \\multicolumn{5}{r}{SemEval2010} \\\\\n",
      " &  & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "candidate_mode & embed_model &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\multirow[c]{3}{*}{in\\_context} & intfloat/e5-base-v2 & 40.35 & 7.34 & 10.19 & 13.04 &  & 42.93 & 4.69 & 7.38 & 8.87 &  & 44.42 & 21.12 & 29.04 & 31.89 &  & 42.68 & 4.34 & 6.83 & 8.65 &  \\\\\n",
      " & paraphrase-multilingual-mpnet-base-v2 & 48.49 & 15.29 & 21.56 & 23.02 &  & 46.23 & 8.12 & 13.82 & 16.85 &  & 44.02 & 20.65 & 27.87 & 30.07 &  & 42.10 & 4.10 & 8.90 & 12.04 &  \\\\\n",
      " & sentence-transformers/sentence-t5-base & 44.17 & 15.59 & 16.63 & 15.70 &  & 33.24 & 3.20 & 4.87 & 5.50 &  & 39.16 & 14.39 & 21.61 & 25.54 &  & 37.43 & 4.73 & 6.38 & 7.28 &  \\\\\n",
      "\\multirow[c]{3}{*}{mentions\\_no\\_context} & intfloat/e5-base-v2 & 60.52 & 28.61 & 33.17 & 33.14 &  & 48.09 & 10.88 & 14.17 & 15.47 &  & 52.36 & 30.42 & 36.36 & 36.22 &  & 47.49 & 9.48 & 12.78 & 14.64 &  \\\\\n",
      " & paraphrase-multilingual-mpnet-base-v2 & nan & nan & nan & nan & nan & 45.36 & 9.18 & 11.43 & 13.04 &  & 50.45 & 27.66 & 33.14 & 33.62 &  & 44.70 & 8.63 & 11.41 & 12.75 &  \\\\\n",
      " & sentence-transformers/sentence-t5-base & 63.31 & 30.74 & 35.42 & 34.99 &  & 45.12 & 8.56 & 12.18 & 13.12 &  & 52.09 & 30.00 & 35.62 & 35.73 &  & 47.21 & 9.99 & 13.43 & 14.20 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_filter = [\n",
    "    \"intfloat/multilingual-e5-base\",\n",
    "    \"paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"sentence-transformers/sentence-t5-base\",\n",
    "]\n",
    "# 0926.xlsx\n",
    "\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ ( 16, 17, 18, 19, 20, 22, 21, 29, 31, 32, 33, 34, 35, 37, 38, 61, 64, 67, 69, 71, 73, 215, 217,) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"embed_model\",\n",
    "            \"dataset_name\",\n",
    "            \"candidate_mode\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    .set_index([\"candidate_mode\", \"embed_model\", \"dataset_name\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(2)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chp 2 - promptRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrlrrrrlrrrrlrrrrlrrrrl}\n",
      " & dataset_name & \\multicolumn{5}{r}{DUC2001} & \\multicolumn{5}{r}{NUS} & \\multicolumn{5}{r}{Inspec} & \\multicolumn{5}{r}{SemEval2010} & \\multicolumn{5}{r}{PubMed} \\\\\n",
      " &  & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "decoder_prompt & embed_model &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\multirow[c]{2}{*}{TL;DR: This article mainly talks about } & google/flan-t5-base & 59.66 & 28.66 & 32.41 & 32.03 &  & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & 53.34 & 15.59 & 18.92 & 19.82 &  & 42.00 & 17.36 & 17.18 & 16.05 &  \\\\\n",
      " & t5-base & 59.42 & 29.56 & 33.56 & 31.89 &  & 57.72 & 21.69 & 24.85 & 23.54 &  & nan & nan & nan & nan & nan & 55.74 & 17.83 & 21.93 & 22.17 &  & 42.69 & 17.68 & 18.14 & 16.68 &  \\\\\n",
      "TL;DR: This book mainly talks about  & google/flan-t5-base & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan & 53.72 & 31.62 & 35.83 & 35.67 &  & nan & nan & nan & nan & nan & nan & nan & nan & nan & nan \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0926.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ ( 56, 60, 72, 76, 77, 78, 79, 80) ]\n",
    "# fmt: on\n",
    "\n",
    "# 1001.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ (14,16,17,19,21,22,23, 337) ]\n",
    "# fmt: on\n",
    "\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"embed_model\",\n",
    "            \"dataset_name\",\n",
    "            \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    # .set_index([\"decoder_prompt\", \"dataset_name\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(-1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrl}\n",
      "dataset_name & \\multicolumn{5}{r}{DUC2001} \\\\\n",
      " & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "embed_model &  &  &  &  &  \\\\\n",
      "paraphrase-multilingual-mpnet-base-v2 & 54.43 & 22.59 & 26.53 & 27.69 &  \\\\\n",
      "t5-base & 58.22 & 27.26 & 31.58 & 30.78 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1001.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ (28, 123) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"embed_model\",\n",
    "            \"dataset_name\",\n",
    "           #  \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"embed_model\", \"dataset_name\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"DUC2001\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbedRank - Long model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-0927.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrlrrrrlrrrrlrrrrl}\n",
      "candidate_mode & \\multicolumn{5}{r}{mentions_no_context} & \\multicolumn{5}{r}{in_context} & \\multicolumn{5}{r}{global_attention} & \\multicolumn{5}{r}{global_attention_dilated_128} \\\\\n",
      " & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "longformer_attention_window &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "64.000000 & 41.21 & 11.43 & 13.41 & 14.08 &  & 41.52 & 11.21 & 13.84 & 14.63 &  & nan & nan & nan & nan & nan & 41.30 & 10.42 & 13.68 & 14.01 &  \\\\\n",
      "128.000000 & 45.72 & 15.42 & 18.32 & 18.89 &  & 41.37 & 10.39 & 13.37 & 14.34 &  & 36.85 & 5.39 & 7.84 & 9.60 &  & 41.00 & 9.89 & 13.64 & 13.80 &  \\\\\n",
      "256.000000 & 50.17 & 19.09 & 23.74 & 23.84 &  & 40.88 & 9.90 & 12.17 & 13.29 &  & 36.90 & 5.38 & 7.69 & 9.48 &  & 40.74 & 9.59 & 12.29 & 13.53 &  \\\\\n",
      "512.000000 & 54.46 & 23.44 & 27.59 & 27.69 &  & 41.25 & 10.48 & 13.25 & 13.56 &  & 36.82 & 5.29 & 7.79 & 9.23 &  & 41.06 & 10.03 & 12.81 & 13.73 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0927.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ ( 121,122,123,124,125,126,127,128,129,130,131,132,133,134,135) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"longformer_attention_window\",\n",
    "            \"candidate_mode\",\n",
    "            # \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"longformer_attention_window\", \"candidate_mode\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"mentions_no_context\", \"in_context\", 'global_attention', \"global_attention_dilated_128\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "# mi = pd.MultiIndex.from_product([[\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],[\"_base_nDCG\",\"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\"]])\n",
    "\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrlrrrrlrrrrlrrrrl}\n",
      "dataset_name & \\multicolumn{5}{r}{DUC2001} & \\multicolumn{5}{r}{NUS} & \\multicolumn{5}{r}{Inspec} & \\multicolumn{5}{r}{SemEval2010} \\\\\n",
      " & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "embed_model &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "[longformer]intfloat/e5-base-v2 & 36.82 & 5.29 & 7.79 & 9.23 &  & 32.91 & 2.15 & 3.28 & 3.63 &  & 44.73 & 21.43 & 29.48 & 32.40 &  & nan & nan & nan & nan &  \\\\\n",
      "[longformer]paraphrase-multilingual-mpnet-base-v2 & 38.82 & 7.41 & 9.99 & 12.06 &  & 34.51 & 1.77 & 3.62 & 4.05 &  & 43.37 & 19.73 & 26.79 & 30.04 &  & nan & nan & nan & nan &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Longmodels baseline\n",
    "# 1001.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ (1,2,3,4,5,6,7,8) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"embed_model\",\n",
    "            \"dataset_name\",\n",
    "            # \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"embed_model\", \"dataset_name\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(-1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\" ],\n",
    "        # [\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MD KPE\n",
    "\n",
    "## EmbedRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrlrrrrlrrrrlrrrrl}\n",
      " & md_strategy & \\multicolumn{5}{r}{RRF} & \\multicolumn{5}{r}{MEAN} & \\multicolumn{5}{r}{MEANTOPMAX} & \\multicolumn{5}{r}{MAX} \\\\\n",
      " &  & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "embed_model & no_position_feature &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\multirow[c]{2}{*}{sentence-t5-base} & 0.000000 & 50.41 & 4.30 & 5.40 & 7.00 &  & 64.07 & 7.65 & 14.44 & 18.92 &  & 65.55 & 8.87 & 14.73 & 19.98 &  & 66.24 & 9.68 & 15.39 & 19.86 &  \\\\\n",
      " & 1.000000 & 50.41 & 4.30 & 5.40 & 7.00 &  & 64.07 & 7.65 & 14.44 & 18.92 &  & 65.55 & 8.87 & 14.73 & 19.98 &  & 66.24 & 9.68 & 15.39 & 19.86 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0927.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ ( 139,140,141,142,143,157,158,159) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"no_position_feature\",\n",
    "            \"embed_model\",\n",
    "            \"md_strategy\",\n",
    "            # \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"embed_model\", \"no_position_feature\", \"md_strategy\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(-1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrlrrrrlrrrrlrrrrl}\n",
      " & md_strategy & \\multicolumn{5}{r}{RRF} & \\multicolumn{5}{r}{MEAN} & \\multicolumn{5}{r}{MEANTOPMAX} & \\multicolumn{5}{r}{MAX} \\\\\n",
      " &  & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "embed_model & no_position_feature &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "sentence-t5-base & 0.000000 & 50.41 & 4.30 & 5.40 & 7.00 &  & 64.07 & 7.65 & 14.44 & 18.92 &  & 65.55 & 8.87 & 14.73 & 19.98 &  & 66.24 & 9.68 & 15.39 & 19.86 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1011.xlsx\n",
    "# fmt: off\n",
    "idx = pd.IndexSlice[ (102, 276, 105, 104) ]\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"no_position_feature\",\n",
    "            \"embed_model\",\n",
    "            \"md_strategy\",\n",
    "            # \"decoder_prompt\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"embed_model\", \"no_position_feature\", \"md_strategy\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(-1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"DUC2001\", \"NUS\", \"Inspec\", \"SemEval2010\", \"PubMed\"],\n",
    "        [\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],\n",
    "        [\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb = pd.read_excel(\"../wandb-export-geo-kpe-multidoc-1019.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrlrrrrlrrrrlrrrrl}\n",
      " & md_strategy & \\multicolumn{5}{r}{RRF} & \\multicolumn{5}{r}{MEAN} & \\multicolumn{5}{r}{MEANTOPMAX} & \\multicolumn{5}{r}{MAX} \\\\\n",
      " &  & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty & nDCG & $F1_5$ & $F1_{10}$ & $F1_{15}$ & empty \\\\\n",
      "embed_model & no_position_feature &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "google/flan-t5-base & 0.000000 & 33.61 & 2.43 & 3.58 & 3.83 &  & 41.16 & 7.48 & 9.58 & 12.02 &  & 44.29 & 6.67 & 11.13 & 13.74 &  & 45.51 & 7.20 & 10.90 & 14.49 &  \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1019.xlsx\n",
    "# fmt: off\n",
    "# idx = pd.IndexSlice[ (9,10,11,12) ] # prompt cross\n",
    "idx = pd.IndexSlice[ (5,6,7,8) ] # prompt no-cross\n",
    "# idx = pd.IndexSlice[ (0,1,2,3,4) ] # embed cross (-pos)\n",
    "# fmt: on\n",
    "\n",
    "t = (\n",
    "    wandb[\n",
    "        [\n",
    "            \"no_position_feature\",\n",
    "            \"embed_model\",\n",
    "            \"md_strategy\",\n",
    "            # \"decoder_prompt\",\n",
    "            \"nDCG\",\n",
    "            \"F1_5\",\n",
    "            \"F1_10\",\n",
    "            \"F1_15\",\n",
    "            \"_base_nDCG\",\n",
    "            \"_base_F1_5\",\n",
    "            \"_base_F1_10\",\n",
    "            \"_base_F1_15\",\n",
    "        ]\n",
    "    ]\n",
    "    .loc[idx, :]\n",
    "    # .set_index([\"decoder_prompt\", \"embed_model\", \"dataset_name\"])\n",
    "    .set_index([\"embed_model\", \"no_position_feature\", \"md_strategy\"])\n",
    "    .assign(empty=\"\")\n",
    "    .unstack(-1)\n",
    "    .swaplevel(0, 1, axis=1)\n",
    "    .sort_index(level=0, axis=1)\n",
    ")\n",
    "mi = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        # [\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\", \"MMR\"],\n",
    "        [\"RRF\",\"MEAN\", \"MEANTOPMAX\", \"MAX\"],\n",
    "        #[\"_base_nDCG\", \"_base_F1_5\", \"_base_F1_10\", \"_base_F1_15\", \"empty\"],\n",
    "        [\"nDCG\", \"F1_5\", \"F1_10\", \"F1_15\", \"empty\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    (t * 100)[mi]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"_base_nDCG\": \"nDCG\",\n",
    "            \"_base_F1_5\": \"$F1_5$\",\n",
    "            \"_base_F1_10\": \"$F1_{10}$\",\n",
    "            \"_base_F1_15\": \"$F1_{15}$\",\n",
    "            \"F1_5\": \"$F1_5$\",\n",
    "            \"F1_10\": \"$F1_{10}$\",\n",
    "            \"F1_15\": \"$F1_{15}$\",\n",
    "        },\n",
    "        level=1,\n",
    "    ).style.format(precision=2)\n",
    "    .format_index(escape=\"latex\", axis=0)\n",
    "    # .highlight_max(props='textbf:--rwrap')\n",
    "    .to_latex()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
