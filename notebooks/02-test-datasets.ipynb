{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyphrase Extraction in multi-documents accounting with geospacial associations\n",
    "\n",
    "This is a exploratory notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Make sure geo-kpe-multidoc environment variables are set.\n",
    "\n",
    "```bash\n",
    "GEO_KPE_MULTIDOC_DATA_PATH=\"data-path\"\n",
    "GEO_KPE_MULTIDOC_MODELS_PATH=\"models-path\"\n",
    "GEO_KPE_MULTIDOC_OUTPUT_PATH=\"output-path\"\n",
    "\n",
    "GEO_KPE_MULTIDOC_MORDECAI_ES_URL=\"ec-instance.compute.amazonaws.com\"\n",
    "\n",
    "GEO_KPE_MULTIDOC_MAPBOX_TOKEN=\"thekey\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 10:09:53.929435: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-23 10:09:54.184309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-23 10:09:54.184331: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-23 10:09:55.302774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-23 10:09:55.303132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-23 10:09:55.303143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-23 10:09:57.050274: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-23 10:09:57.050558: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-23 10:09:57.050580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (darkstar): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from geo_kpe_multidoc.models import EmbedRank, MaskRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKEND_MODEL_NAME = 'longformer-paraphrase-multilingual-mpnet-base-v2'\n",
    "PARSER_NAME = 'en_core_web_trf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"INDUSTRIAL SOCIETY AND ITS FUTURE\n",
    "\n",
    "Introduction\n",
    "\n",
    "1. The Industrial Revolution and its consequences have been a disaster for the human race. They have greatly increased the life-expectancy of those of us who live in \"advanced\" countries, but they have destabilized society, have made life unfulfilling, have subjected human beings to indignities, have led to widespread psychological suffering (in the Third World to physical suffering as well) and have inflicted severe damage on the natural world. The continued development of technology will worsen the situation. It will certainly subject human beings to greater indignities and inflict greater damage on the natural world, it will probably lead to greater social disruption and psychological suffering, and it may lead to increased physical suffering even in \"advanced\" countries.\n",
    "\n",
    "2. The industrial-technological system may survive or it may break down. If it survives, it MAY eventually achieve a low level of physical and psychological suffering, but only after passing through a long and very painful period of adjustment and only at the cost of permanently reducing human beings and many other living organisms to engineered products and mere cogs in the social machine. Furthermore, if the system survives, the consequences will be inevitable: There is no way of reforming or modifying the system so as to prevent it from depriving people of dignity and autonomy.\n",
    "\n",
    "3. If the system breaks down the consequences will still be very painful. But the bigger the system grows the more disastrous the results of its breakdown will be, so if it is to break down it had best break down sooner rather than later.\n",
    "\n",
    "4. We therefore advocate a revolution against the industrial system. This revolution may or may not make use of violence; it may be sudden or it may be a relatively gradual process spanning a few decades. We can't predict any of that. But we do outline in a very general way the measures that those who hate the industrial system should take in order to prepare the way for a revolution against that form of society. This is not to be a POLITICAL revolution. Its object will be to overthrow not governments but the economic and technological basis of the present society.\n",
    "\n",
    "5. In this article we give attention to only some of the negative developments that have grown out of the industrial-technological system. Other such developments we mention only briefly or ignore altogether. This does not mean that we regard these other developments as unimportant. For practical reasons we have to confine our discussion to areas that have received insufficient public attention or in which we have something new to say. For example, since there are well-developed environmental and wilderness movements, we have written very little about environmental degradation or the destruction of wild nature, even though we consider these to be highly important.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/helder/doc/mecd/thesis/models/longformer-paraphrase-multilingual-mpnet-base-v2 were not used when initializing XLMRobertaModel: ['encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.7.attention.self.key_global.weight', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.6.attention.self.value_global.weight', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.7.attention.self.key_global.bias', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.11.attention.self.value_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.9.attention.self.key_global.bias', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.9.attention.self.key_global.weight', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.9.attention.self.value_global.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False0\n",
      "Embed Doc = 0.25\n",
      "Embed Candidates = 2.73\n",
      "document 0 processed\n",
      "\n",
      "Embed Rank\n",
      "[('widespread psychological suffering', 0.91977453), ('human beings', 0.894561), ('situation', 0.89339185), ('life unfulfilling', 0.8926681), ('psychological suffering', 0.8493317)]\n",
      "===========================================\n",
      "['widespread psychological suffering', 'human beings', 'situation', 'life unfulfilling', 'psychological suffering', 'continued development', 'physical suffering', 'severe damage', 'natural world', 'indignities', 'technology', 'human race', 'Industrial Revolution', 'life-expectancy', 'society', 'revolution', 'disaster', 'INDUSTRIAL SOCIETY', 'consequences', 'countries', 'industrial system', 'industrial-technological system', 'present society', 'FUTURE', 'greater social disruption', 'negative developments', 'Other such developments', 'well-developed environmental', 'environmental degradation', 'social machine', 'other developments', 'technological basis', 'greater indignities', 'POLITICAL revolution', 'discussion', 'Third World', 'article', 'practical reasons', 'destruction', 'few decades', 'Introduction', 'greater damage', 'system', 'adjustment', 'example', 'measures', 'products', 'gradual process', 'breakdown', 'use', 'insufficient public attention', 'organisms', 'general way', 'areas', 'governments', 'dignity', 'order', 'autonomy', 'people', 'results', 'way', 'wilderness movements', 'attention', 'form', 'violence', 'wild nature', 'mere cogs', 'object', 'cost', 'low level', 'painful period']\n"
     ]
    }
   ],
   "source": [
    "kpe_embed = EmbedRank( BACKEND_MODEL_NAME, PARSER_NAME)\n",
    "\n",
    "top_n, candidate_set = kpe_embed.extract_kp_from_doc(doc=doc, top_n=5, min_len=2)\n",
    "print(\"Embed Rank\")\n",
    "print(top_n)\n",
    "print(\"===========================================\")\n",
    "print(candidate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/helder/doc/mecd/thesis/models/longformer-paraphrase-multilingual-mpnet-base-v2 were not used when initializing XLMRobertaModel: ['encoder.layer.1.attention.self.query_global.weight', 'encoder.layer.1.attention.self.value_global.weight', 'encoder.layer.4.attention.self.query_global.bias', 'encoder.layer.0.attention.self.query_global.bias', 'encoder.layer.2.attention.self.query_global.weight', 'encoder.layer.9.attention.self.query_global.bias', 'encoder.layer.6.attention.self.key_global.weight', 'encoder.layer.0.attention.self.value_global.bias', 'encoder.layer.7.attention.self.query_global.bias', 'encoder.layer.5.attention.self.key_global.bias', 'encoder.layer.0.attention.self.value_global.weight', 'encoder.layer.8.attention.self.query_global.bias', 'encoder.layer.5.attention.self.value_global.weight', 'encoder.layer.0.attention.self.key_global.weight', 'encoder.layer.4.attention.self.value_global.weight', 'encoder.layer.7.attention.self.key_global.weight', 'encoder.layer.11.attention.self.query_global.weight', 'encoder.layer.6.attention.self.value_global.bias', 'encoder.layer.4.attention.self.query_global.weight', 'encoder.layer.6.attention.self.value_global.weight', 'encoder.layer.10.attention.self.query_global.bias', 'encoder.layer.7.attention.self.query_global.weight', 'encoder.layer.10.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.bias', 'encoder.layer.4.attention.self.value_global.bias', 'encoder.layer.9.attention.self.query_global.weight', 'encoder.layer.0.attention.self.key_global.bias', 'encoder.layer.2.attention.self.query_global.bias', 'encoder.layer.10.attention.self.key_global.weight', 'encoder.layer.10.attention.self.value_global.bias', 'encoder.layer.2.attention.self.key_global.weight', 'encoder.layer.6.attention.self.query_global.bias', 'encoder.layer.11.attention.self.key_global.bias', 'encoder.layer.8.attention.self.value_global.weight', 'encoder.layer.8.attention.self.key_global.bias', 'encoder.layer.7.attention.self.key_global.bias', 'encoder.layer.5.attention.self.value_global.bias', 'encoder.layer.2.attention.self.key_global.bias', 'encoder.layer.3.attention.self.value_global.weight', 'encoder.layer.1.attention.self.key_global.bias', 'encoder.layer.11.attention.self.value_global.weight', 'encoder.layer.4.attention.self.key_global.weight', 'encoder.layer.11.attention.self.value_global.bias', 'encoder.layer.5.attention.self.key_global.weight', 'encoder.layer.1.attention.self.value_global.bias', 'encoder.layer.6.attention.self.key_global.bias', 'encoder.layer.1.attention.self.key_global.weight', 'encoder.layer.7.attention.self.value_global.bias', 'encoder.layer.3.attention.self.query_global.weight', 'encoder.layer.1.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.bias', 'encoder.layer.10.attention.self.value_global.weight', 'encoder.layer.9.attention.self.key_global.bias', 'encoder.layer.11.attention.self.query_global.bias', 'encoder.layer.8.attention.self.value_global.bias', 'encoder.layer.5.attention.self.query_global.weight', 'encoder.layer.5.attention.self.query_global.bias', 'encoder.layer.8.attention.self.key_global.weight', 'encoder.layer.2.attention.self.value_global.weight', 'encoder.layer.3.attention.self.query_global.bias', 'encoder.layer.3.attention.self.key_global.weight', 'encoder.layer.0.attention.self.query_global.weight', 'encoder.layer.2.attention.self.value_global.bias', 'encoder.layer.8.attention.self.query_global.weight', 'encoder.layer.9.attention.self.key_global.weight', 'encoder.layer.10.attention.self.query_global.weight', 'encoder.layer.11.attention.self.key_global.weight', 'encoder.layer.9.attention.self.value_global.weight', 'encoder.layer.4.attention.self.key_global.bias', 'encoder.layer.6.attention.self.query_global.weight', 'encoder.layer.7.attention.self.value_global.weight', 'encoder.layer.9.attention.self.value_global.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False0\n",
      "Embed Doc = 0.34\n",
      "Embed Candidates = 14.48\n",
      "document 0 processed\n",
      "\n",
      "Mask Rank\n",
      "[('INDUSTRIAL SOCIETY', 0.06169772148132324), ('FUTURE', 0.043590426445007324), ('Industrial Revolution', 0.025974154472351074), ('disaster', 0.018137454986572266), ('human race', 0.012478113174438477)]\n",
      "===========================================\n",
      "['INDUSTRIAL SOCIETY', 'FUTURE', 'Industrial Revolution', 'disaster', 'human race', 'consequences', 'Introduction', 'life-expectancy', 'human beings', 'countries', 'natural world', 'society', 'life unfulfilling', 'situation', 'technology', 'severe damage', 'widespread psychological suffering', 'continued development', 'psychological suffering', 'Third World', 'indignities', 'physical suffering', 'attention', 'Other such developments', 'form', 'people', 'order', 'dignity', 'autonomy', 'object', 'present society', 'way', 'wild nature', 'governments', 'use', 'adjustment', 'technological basis', 'example', 'general way', 'article', 'well-developed environmental', 'environmental degradation', 'painful period', 'revolution', 'measures', 'organisms', 'POLITICAL revolution', 'greater damage', 'practical reasons', 'discussion', 'greater social disruption', 'social machine', 'gradual process', 'low level', 'other developments', 'mere cogs', 'wilderness movements', 'greater indignities', 'industrial system', 'results', 'negative developments', 'cost', 'destruction', 'breakdown', 'products', 'few decades', 'areas', 'insufficient public attention', 'system', 'violence', 'industrial-technological system']\n"
     ]
    }
   ],
   "source": [
    "kpe_mask = MaskRank( BACKEND_MODEL_NAME, PARSER_NAME)\n",
    "top_n, candidate_set = kpe_mask.extract_kp_from_doc(doc=doc, top_n=5, min_len=2)\n",
    "print(\"Mask Rank\")\n",
    "print(top_n)\n",
    "print(\"===========================================\")\n",
    "print(candidate_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6192d2b8519ba1dc6668f1bfbce40557ee186aa5dae8ab284b50dd4471395d02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
